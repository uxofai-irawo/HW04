{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffuser Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install diffusers transformers accelerate safetensors torchvision --upgrade\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "from diffusers import AutoPipelineForImage2Image, AutoPipelineForText2Image\n",
    "from diffusers import AutoPipelineForInpainting, ControlNetModel\n",
    "from diffusers import DPMSolverMultistepScheduler, EulerDiscreteScheduler, UniPCMultistepScheduler\n",
    "from diffusers import StableDiffusionPipeline as SDPipeline\n",
    "from diffusers import StableDiffusionControlNetPipeline as SDCNPipeline\n",
    "from diffusers import StableDiffusionImageVariationPipeline as SDIVPipeline\n",
    "\n",
    "from SD_utils import StableDiffusionImageVariationProcessor as SDIVProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Stable Diffusion](https://huggingface.co/stabilityai/stable-diffusion-2)\n",
    "\n",
    "Open-source image generation architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = SDPipeline.from_pretrained(\n",
    "  \"runwayml/stable-diffusion-v1-5\",\n",
    "  #\"CompVis/stable-diffusion-v1-4\",\n",
    "  #\"stabilityai/stable-diffusion-2-1\",\n",
    "  safety_checker=None,\n",
    "  torch_dtype=torch.float16\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De-noising is the process of turning random pixels into images:\n",
    "\n",
    "<img src=\"../imgs/denoise.jpg\" width=\"450px\">\n",
    "\n",
    "The pipeline scheduler determines the rate of de-noising:\n",
    "\n",
    "<img src=\"../imgs/scheduler.jpg\" width=\"450px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "# pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)\n",
    "# pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(\"an egg walking around on the moon\", num_inference_steps=32)\n",
    "display(out[\"images\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reproduce results by using a controllable random number generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator().manual_seed(1010)\n",
    "out = pipe(\"an egg walking around on the moon\", num_inference_steps=32, generator=generator)\n",
    "display(out[\"images\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control Net\n",
    "\n",
    "Almost like add-ons/plugins for the Stable-Diffusion architecture.\n",
    "\n",
    "Expands our options for guiding the model.\n",
    "\n",
    "#### [Scribble](https://huggingface.co/lllyasviel/sd-controlnet-scribble)\n",
    "\n",
    "<img src=\"../imgs/scribble_00.jpg\" width=\"200px\">\n",
    "<img src=\"../imgs/scribble_01.jpg\" width=\"200px\">\n",
    "\n",
    "#### [Depth](https://huggingface.co/lllyasviel/sd-controlnet-depth)\n",
    "\n",
    "<img src=\"../imgs/depth_00.jpg\" width=\"200px\">\n",
    "<img src=\"../imgs/depth_01.jpg\" width=\"200px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlnet = ControlNetModel.from_pretrained(\n",
    "  \"lllyasviel/sd-controlnet-scribble\",\n",
    "  # \"lllyasviel/sd-controlnet-depth\",\n",
    "  torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "pipe = SDCNPipeline.from_pretrained(\n",
    "  \"runwayml/stable-diffusion-v1-5\",\n",
    "  controlnet=controlnet,\n",
    "  safety_checker=None,\n",
    "  torch_dtype=torch.float16\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "# pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)\n",
    "# pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"../imgs/scribble_00.jpg\").convert(\"RGB\")\n",
    "out = pipe(\"person\", im, num_inference_steps=20)\n",
    "display(out[\"images\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [SD Turbo](https://huggingface.co/stabilityai/sd-turbo)\n",
    "\n",
    "Distilled version of Stable-Diffusion.\n",
    "\n",
    "https://www.reddit.com/r/StableDiffusion/comments/1e6cq09/physical_interfaces_realtime_img2img_diffusion/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = AutoPipelineForText2Image.from_pretrained(\n",
    "  \"stabilityai/sd-turbo\",\n",
    "  # \"stabilityai/sdxl-turbo\",\n",
    "  torch_dtype=torch.float16,\n",
    "  variant=\"fp16\"\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A cinematic shot of a baby racoon wearing an intricate italian priest robe.\"\n",
    "out = pipe(prompt=prompt, num_inference_steps=1, guidance_scale=0.0, num_images_per_prompt=4)\n",
    "display(out[\"images\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = AutoPipelineForImage2Image.from_pretrained(\n",
    "  \"stabilityai/sd-turbo\",\n",
    "  # \"stabilityai/sdxl-turbo\",\n",
    "  torch_dtype=torch.float16,\n",
    "  variant=\"fp16\"\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"../imgs/scribble_01.jpg\").convert(\"RGB\")\n",
    "prompt = \"cat wizard, gandalf, lord of the rings, detailed, fantasy, cute, adorable, Pixar, Disney, 8k\"\n",
    "out = pipe(prompt, image=im, num_inference_steps=2, strength=0.5, guidance_scale=0.0)\n",
    "display(out[\"images\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Inpainting](https://huggingface.co/docs/diffusers/en/using-diffusers/inpaint)\n",
    "\n",
    "Only generate parts of an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = AutoPipelineForInpainting.from_pretrained(\n",
    "  #\"runwayml/stable-diffusion-inpainting\",\n",
    "  #\"stable-diffusion-v1-5/stable-diffusion-inpainting\",\n",
    "  \"stabilityai/stable-diffusion-2-inpainting\",\n",
    "  torch_dtype=torch.float16,\n",
    "  variant=\"fp16\"\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"../imgs/landscape.jpg\")\n",
    "mask = Image.open(\"../imgs/landscape_mask.jpg\").filter(ImageFilter.GaussianBlur((16,0)))\n",
    "iw,ih = im.size\n",
    "\n",
    "display(im)\n",
    "display(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"bob ross oil painting of nature landscape with trees, detailed brushstrokes, mountains, lake, rocks\"\n",
    "output = pipe(prompt=prompt, image=im, mask_image=mask, num_inference_steps=24, width=iw, height=ih)\n",
    "display(output.images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Image Variation](https://huggingface.co/lambdalabs/sd-image-variations-diffusers)\n",
    "\n",
    "Get variations of an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = SDIVPipeline.from_pretrained(\n",
    "  \"lambdalabs/sd-image-variations-diffusers\",\n",
    "  revision=\"v2.0\",\n",
    "  safety_checker=None\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "# pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)\n",
    "# pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"../imgs/scribble_01.jpg\")\n",
    "input = SDIVProcessor(im).to(\"cuda\").unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(input, guidance_scale=3, num_inference_steps=32)\n",
    "display(out[\"images\"][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gradio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
